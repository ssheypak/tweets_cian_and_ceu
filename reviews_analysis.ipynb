{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ–∫—Å—Ç –∏ –∏—â–µ–º, –ø–æ –∫–∞–∫–æ–º—É —Å–∏–º–≤–æ–ª—É —Ä–∞–∑–±–∏—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/reviews.txt\", \"r\") as file:\n",
    "    text = file.read()\n",
    "    \n",
    "text = text.lstrip(\"INTELLIGENCE\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1.215', 1244),\n",
       " ('–∏', 640),\n",
       " ('–Ω–µ', 636),\n",
       " ('1.214.1', 484),\n",
       " ('–≤', 432),\n",
       " ('—Å–¥–∞–≤–∞—Ç—å', 430),\n",
       " ('–∫–æ–º—É', 405),\n",
       " ('–Ω–∞', 259),\n",
       " ('—á—Ç–æ', 257),\n",
       " ('—Ç–æ–ª—å–∫–æ', 234),\n",
       " ('—è', 217),\n",
       " ('–ù–µ', 205),\n",
       " ('–∑–∞', 192),\n",
       " ('–î–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è', 182),\n",
       " ('–ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ', 179),\n",
       " ('–∫–≤–∞—Ä—Ç–∏—Ä—É', 176),\n",
       " ('–∞', 164),\n",
       " ('—Ö–æ—á—É', 163),\n",
       " ('—Å', 158),\n",
       " ('–Ø', 146),\n",
       " ('–¥–ª—è', 145),\n",
       " ('—ç—Ç–æ', 144),\n",
       " ('—Å–ª–∞–≤—è–Ω', 139),\n",
       " ('–∫–∞–∫', 134),\n",
       " ('–≤—ã', 133)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(tokens)\n",
    "c.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–±–∏–≤–∞–µ–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "reviews = [x.strip().lower() for x in re.split(\"1.215|1.214.1\", text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–∏–∫–æ–≤ –∂–∏–ª—å—è. —Ä—É—Å–æ—Ñ–æ–±—ã!!!',\n",
       " '—É–∂–∞—Å –∏–∑ –∑–∞ —É–±—Ä–∞–Ω–Ω–æ–π –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —É–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –∫–æ—Å—Ç—Ä–µ –ø—Ä–∏–µ—Ö–∞–ª–∏ –∏ —á—É—Ç—å –Ω–µ –∏–∑–±–∏–ª–∏ –Ω–µ—Ä—É—Å—Å–∫–∏–µ –∑–∞ —Ç–æ —á—Ç–æ —è –∏–º –æ—Ç–∫–∞–∑–∞–ª! —É–¥–∞–ª—è—é –Ω–∞–≤—Å–µ–≥–¥–∞!!!!',\n",
       " '—è –±—É–¥—É —Å–¥–∞–≤–∞—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É,–∫–æ–º—É —Ö–æ—á—É –∏ —ç—Ç–æ –±—É–¥—É —Å–ª–∞–≤—è–Ω–µ!üôãüèº\\u200d‚ôÇÔ∏è‚òÄÔ∏è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —É–∂–∞—Å–Ω–æ–µ,–∏ –ø—Ä–æ–≤–µ–¥–∞–π—Ç–µ —Ç–∞–º —Å–≤–æ–∏ –∞–∫—Ü–∏–∏ –∫–æ–º–ø–∞–Ω–∏–∏,–∫–∞–∫ –≤—ã –∏–≥—Ä–∞–µ—Ç–µ –≤ —Ç–æ–ª–µ—Ä–∞—Å—Ç–æ–≤ –∏ –∞–∫—Ü–∏–∏ –∏–¥—É—Ç –≤ —É–ø–∞–¥–æ–∫‚Ä¶',\n",
       " '—Å–ø–∞—Å–∏–±–æ —Ü–∏–∞–Ω! –ø—Ä–∏–¥–µ—Ç—Å—è —Ä–∞–∑–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å —Å –ª—é–¥—å–º–∏, –ø–ª–æ—Ö–æ –∑–Ω–∞—é—â–∏–º–∏ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç—è—Ç –∑–∞—Å–µ–ª–∏—Ç—å—Å—è –≤—Å–µ–º —Ç–∞–±—É–Ω–æ–º –≤ –º–æ—é –∫–≤–∞—Ä—Ç–∏—Ä—É. —Å–ø–∞—Å–∏–±–æ, –≤—ã —Å–∞–º–∏ –∂–µ –∏ —É—Å–ª–æ–∂–Ω–∏–ª–∏ –ø–æ–∏—Å–∫ –∫–≤–∞—Ä—Ç–∏—Ä—ã –∏–Ω–æ—Å—Ç—Ä–∞–Ω—Ü–∞–º –±–ª–∏–∂–Ω–µ–≥–æ –∑–∞—Ä—É–±–µ–∂—å—è, —Ç–µ–ø–µ—Ä—å –∏–º –ø—Ä–∏–¥–µ—Ç—Å—è –ø–æ–±–µ–≥–∞—Ç—å –∏ –ø–æ—Ç—Ä–∞—Ç—å –∫—É—á—É –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ –ø–æ–∏—Å–∫ —á–µ–ª–æ–≤–µ–∫–∞, –∫–æ—Ç–æ—Ä–æ–º—É –±–µ–∑—Ä–∞–∑–ª–∏—á–Ω–æ –Ω–∞ —Ç–æ, –∫–æ–º—É —Å–¥–∞–≤–∞—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É',\n",
       " '–ø–æ—á–µ–º—É —Ä–µ—à–∞—Ç—å –∫–æ–º—É-—Ç–æ –∫–æ–º—É —è —Ö–æ—á—É —Å–¥–∞–≤–∞—Ç—å –∫–≤–∞—Ä—Ç–∏—Ä—É? –ø–æ—á–µ–º—É —Ä–µ—à–∞–µ—Ç–µ –≤—ã, —á—Ç–æ –¥–µ–ª–∞—Ç—å —Å –º–æ–µ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å—é, –∑–∞—Ö–æ—á—É —Ç–æ–ª—å–∫–æ —Å–æ–±–∞–∫–∞–º —Å–¥–∞–≤–∞—Ç—å –±—É–¥—É, –∞ –∑–∞—Ö–æ—á—É –±—Ä–∏–≥–∞–¥—É —Å—Ç—Ä–æ–∏—Ç–µ–ª–µ–π, —ç—Ç–æ –Ω–µ –ø—Ä–∞–≤–∏–ª–∞ –∞ –±—Ä–µ–¥.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º: —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –∏ –±–µ–∑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('russian')\n",
    "stop_words.extend([x for x in string.punctuation] + [\"¬´\", \"¬ª\", \"—ç—Ç–æ\", \"—Ü–∏–∞–Ω\", \"!!!\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\n",
    "def normalize(x):\n",
    "    return morph.parse(x)[0].normal_form\n",
    "\n",
    "def extract_POS(x):\n",
    "    return morph.parse(x)[0].tag.POS or \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize(\"—Å–ª–∞–≤—è–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_reviews = []\n",
    "normalized_reviews = []\n",
    "\n",
    "for r in reviews:\n",
    "    tokens = [x for x in WordPunctTokenizer().tokenize(r) if x not in stop_words]\n",
    "    tokenized_reviews.append(tokens)\n",
    "    normalized_reviews.append([normalize(x) for x in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.hist([len(x) for x in tokenized_reviews], bins=np.arange(0, 130, 2), rwidth=1)\n",
    "plt.grid()\n",
    "plt.title(\"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤ –≤ –æ—Ç–∑—ã–≤–µ (–ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤)\")\n",
    "plt.xticks(np.arange(0, 130, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_arr = []\n",
    "for r in tokenized_reviews:\n",
    "    POS_arr += [extract_POS(x) for x in r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_counter = Counter(POS_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ntop = len(pos_counter)\n",
    "xs = np.arange(len(pos_counter))\n",
    "ys = [y for x, y in pos_counter.most_common(ntop)][::-1]\n",
    "labels = [x for x, y in pos_counter.most_common(ntop)][::-1]\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.title(\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–≤ –ø–æ —á–∞—Å—Ç—è–º —Ä–µ—á–∏\")\n",
    "\n",
    "plt.barh(xs, ys)\n",
    "plt.yticks(xs, labels=[x + \"\" for x in labels])\n",
    "plt.ylabel(\"Labels\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Ç—ç–≥–æ–≤:\n",
    "https://pymorphy2.readthedocs.io/en/stable/user/grammemes.html#grammeme-docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°—á–∏—Ç–∞–µ–º —á–∞—Å—Ç–æ—Ç—ã  n-–≥—Ä–∞–º–º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_n_grams(arr, n, sep=\" \"):\n",
    "    return [sep.join(arr[i:i+n]) for i in range(len(arr) - min(len(arr), n) + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = defaultdict(list)\n",
    "for tokens in tokenized_reviews:\n",
    "    for i in range(1, N + 1):\n",
    "        n_grams[i] += make_n_grams(tokens, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = {}\n",
    "for key, value in n_grams.items():\n",
    "    counters[key] = Counter(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols = 1\n",
    "nrows = math.ceil(N / ncols)\n",
    "ntop = 30\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10 * ncols, 10 * nrows), ncols=ncols, nrows=nrows)\n",
    "\n",
    "keys = []\n",
    "\n",
    "for i, key in enumerate(counters.keys()):\n",
    "    ax = axs.reshape(-1)[i]\n",
    "    xs = np.arange(ntop)\n",
    "    ys = [y for x, y in counters[key].most_common(ntop)][::-1]\n",
    "    labels = [x for x, y in counters[key].most_common(ntop)][::-1]\n",
    "    ax.grid()\n",
    "    ax.barh(xs, ys)\n",
    "    ax.set_yticks(xs)\n",
    "    ax.set_yticklabels(labels, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ –∂–µ —Å–∞–º–æ–µ, –Ω–æ —Å –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grams = defaultdict(list)\n",
    "for tokens in normalized_reviews:\n",
    "    for i in range(1, N + 1):\n",
    "        n_grams[i] += make_n_grams(tokens, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counters = {}\n",
    "for key, value in n_grams.items():\n",
    "    counters[key] = Counter(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ncols = 1\n",
    "nrows = math.ceil(N / ncols)\n",
    "ntop = 30\n",
    "\n",
    "fig, axs = plt.subplots(figsize=(10 * ncols, 10 * nrows), ncols=ncols, nrows=nrows)\n",
    "\n",
    "keys = []\n",
    "\n",
    "for i, key in enumerate(counters.keys()):\n",
    "    ax = axs.reshape(-1)[i]\n",
    "    xs = np.arange(ntop)\n",
    "    ys = [y for x, y in counters[key].most_common(ntop)][::-1]\n",
    "    labels = [x for x, y in counters[key].most_common(ntop)][::-1]\n",
    "    ax.grid()\n",
    "    ax.barh(xs, ys)\n",
    "    ax.set_yticks(xs)\n",
    "    ax.set_yticklabels(labels, rotation=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–µ–∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–º–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"—Å–ª–∞–≤—è–Ω–∏–Ω —Å–ª–∞–≤—è–Ω–∏–Ω\",\n",
    "    \"–¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è —Å–ª–∞–≤—è–Ω–∏–Ω –¥–∏—Å–∫—Ä–∏–º–∏–Ω–∞—Ü–∏—è —Å–ª–∞–≤—è–Ω–∏–Ω\"\n",
    "]\n",
    "\n",
    "dct = {x:[] for x in examples}\n",
    "\n",
    "for i, x in enumerate(normalized_reviews):\n",
    "    key = \" \".join(x)\n",
    "    if key in examples:\n",
    "        dct[key].append(reviews[i])\n",
    "        \n",
    "for key, value in dct.items():\n",
    "    print(key)\n",
    "    for x in value:\n",
    "        print(\"\\t- \" + x)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ \n",
    "–ö–∞–∫ –≤ https://habr.com/ru/post/472988/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''The platform provides universal access to the world's best education, partnering with top universities and organizations to offer courses online.'''\n",
    "\n",
    "analysisPol = TextBlob(sentence).polarity\n",
    "analysisSub = TextBlob(sentence).subjectivity\n",
    "\n",
    "analysisPol,analysisSub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = '''–í—Å—ë –æ—á–µ–Ω—å –ø–ª–æ—Ö–æ —è —Ç–∞–∫ –±–æ–ª—å—à–µ –Ω–µ –º–æ–≥—É'''\n",
    "\n",
    "analysisPol = TextBlob(sentence).polarity\n",
    "analysisSub = TextBlob(sentence).subjectivity\n",
    "\n",
    "analysisPol,analysisSub"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
